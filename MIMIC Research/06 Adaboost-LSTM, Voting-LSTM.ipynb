{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a803f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6182, 10, 4069), (6182,), (1545, 10, 4069), (1545,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random    \n",
    "\n",
    "# ---------------------------\n",
    "seed_num = 42\n",
    "# ---------------------------\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4069).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc054433",
   "metadata": {},
   "source": [
    "# Adaboost-LSTM\n",
    "- https://github.com/veniversum/keras/blob/9a401eb2e184fda7238a6259c1b8b02c645e4e9c/keras/wrappers/scikit_learn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2e4ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.utils\n",
    "\n",
    "\"\"\"Wrapper for using the Scikit-Learn API with Keras models.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import types\n",
    "\n",
    "import sklearn\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.generic_utils import has_arg\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "class BaseWrapper(object):\n",
    "    \"\"\"Base class for the Keras scikit-learn wrapper.\n",
    "\n",
    "    Warning: This class should not be used directly.\n",
    "    Use descendant classes instead.\n",
    "\n",
    "    # Arguments\n",
    "        build_fn: callable function or class instance\n",
    "        **sk_params: model parameters & fitting parameters\n",
    "\n",
    "    The `build_fn` should construct, compile and return a Keras model, which\n",
    "    will then be used to fit/predict. One of the following\n",
    "    three values could be passed to `build_fn`:\n",
    "    1. A function\n",
    "    2. An instance of a class that implements the `__call__` method\n",
    "    3. None. This means you implement a class that inherits from either\n",
    "    `KerasClassifier` or `KerasRegressor`. The `__call__` method of the\n",
    "    present class will then be treated as the default `build_fn`.\n",
    "\n",
    "    `sk_params` takes both model parameters and fitting parameters. Legal model\n",
    "    parameters are the arguments of `build_fn`. Note that like all other\n",
    "    estimators in scikit-learn, `build_fn` should provide default values for\n",
    "    its arguments, so that you could create the estimator without passing any\n",
    "    values to `sk_params`.\n",
    "\n",
    "    `sk_params` could also accept parameters for calling `fit`, `predict`,\n",
    "    `predict_proba`, and `score` methods (e.g., `epochs`, `batch_size`).\n",
    "    fitting (predicting) parameters are selected in the following order:\n",
    "\n",
    "    1. Values passed to the dictionary arguments of\n",
    "    `fit`, `predict`, `predict_proba`, and `score` methods\n",
    "    2. Values passed to `sk_params`\n",
    "    3. The default values of the `keras.models.Sequential`\n",
    "    `fit`, `predict`, `predict_proba` and `score` methods\n",
    "\n",
    "    When using scikit-learn's `grid_search` API, legal tunable parameters are\n",
    "    those you could pass to `sk_params`, including fitting parameters.\n",
    "    In other words, you could use `grid_search` to search for the best\n",
    "    `batch_size` or `epochs` as well as the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.check_params(sk_params)\n",
    "\n",
    "    def check_params(self, params):\n",
    "        \"\"\"Checks for user typos in `params`.\n",
    "\n",
    "        # Arguments\n",
    "            params: dictionary; the parameters to be checked\n",
    "\n",
    "        # Raises\n",
    "            ValueError: if any member of `params` is not a valid argument.\n",
    "        \"\"\"\n",
    "        legal_params_fns = [Sequential.fit, Sequential.predict,\n",
    "                            Sequential.predict_classes, Sequential.evaluate]\n",
    "        if self.build_fn is None:\n",
    "            legal_params_fns.append(self.__call__)\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            legal_params_fns.append(self.build_fn.__call__)\n",
    "        else:\n",
    "            legal_params_fns.append(self.build_fn)\n",
    "\n",
    "        for params_name in params:\n",
    "            for fn in legal_params_fns:\n",
    "                if has_arg(fn, params_name):\n",
    "                    break\n",
    "            else:\n",
    "                if params_name != 'nb_epoch':\n",
    "                    raise ValueError(\n",
    "                        '{} is not a legal parameter'.format(params_name))\n",
    "\n",
    "    def get_params(self, **params):\n",
    "        \"\"\"Gets parameters for this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: ignored (exists for API compatibility).\n",
    "\n",
    "        # Returns\n",
    "            Dictionary of parameter names mapped to their values.\n",
    "        \"\"\"\n",
    "        res = copy.deepcopy(self.sk_params)\n",
    "        res.update({'build_fn': self.build_fn})\n",
    "        return res\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Sets the parameters of this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: Dictionary of parameter names mapped to their values.\n",
    "\n",
    "        # Returns\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.check_params(params)\n",
    "        self.sk_params.update(params)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x, y, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "        \"\"\"\n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            self.model = self.build_fn(\n",
    "                **self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n",
    "        fit_args.update(kwargs)\n",
    "\n",
    "        history = self.model.fit(x, y, **fit_args)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def filter_sk_params(self, fn, override=None):\n",
    "        \"\"\"Filters `sk_params` and returns those in `fn`'s arguments.\n",
    "\n",
    "        # Arguments\n",
    "            fn : arbitrary function\n",
    "            override: dictionary, values to override `sk_params`\n",
    "\n",
    "        # Returns\n",
    "            res : dictionary containing variables\n",
    "                in both `sk_params` and `fn`'s arguments.\n",
    "        \"\"\"\n",
    "        override = override or {}\n",
    "        res = {}\n",
    "        for name, value in self.sk_params.items():\n",
    "            if has_arg(fn, name):\n",
    "                res.update({name: value})\n",
    "        res.update(override)\n",
    "        return res\n",
    "\n",
    "\n",
    "class KerasClassifier(BaseWrapper):\n",
    "    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: In case of invalid shape for `y` argument.\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        if sample_weight is not None:\n",
    "            kwargs['sample_weight'] = sample_weight\n",
    "        return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        \"\"\"Returns the class predictions for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            preds: array-like, shape `(n_samples,)`\n",
    "                Class predictions.\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n",
    "        classes = self.model.predict_classes(x, **kwargs)\n",
    "        return self.classes_[classes]\n",
    "\n",
    "    def predict_proba(self, x, **kwargs):\n",
    "        \"\"\"Returns class probability estimates for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            proba: array-like, shape `(n_samples, n_outputs)`\n",
    "                Class probability estimates.\n",
    "                In the case of binary classification,\n",
    "                to match the scikit-learn API,\n",
    "                will return an array of shape `(n_samples, 2)`\n",
    "                (instead of `(n_sample, 1)` as in Keras).\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n",
    "        probs = self.model.predict_proba(x, **kwargs)\n",
    "\n",
    "        # check if binary classification\n",
    "        if probs.shape[1] == 1:\n",
    "            # first column is probability of class 0 and second is of class 1\n",
    "            probs = np.hstack([1 - probs, probs])\n",
    "        return probs\n",
    "\n",
    "    def score(self, x, y, **kwargs):\n",
    "        \"\"\"Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.evaluate`.\n",
    "\n",
    "        # Returns\n",
    "            score: float\n",
    "                Mean accuracy of predictions on `x` wrt. `y`.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: If the underlying model isn't configured to\n",
    "                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n",
    "                the `.compile()` method of the model.\n",
    "        \"\"\"\n",
    "        y = np.searchsorted(self.classes_, y)\n",
    "        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        outputs = self.model.evaluate(x, y, **kwargs)\n",
    "        if not isinstance(outputs, list):\n",
    "            outputs = [outputs]\n",
    "        for name, output in zip(self.model.metrics_names, outputs):\n",
    "            if name == 'acc':\n",
    "                return output\n",
    "        raise ValueError('The model is not configured to compute accuracy. '\n",
    "                         'You should pass `metrics=[\"accuracy\"]` to '\n",
    "                         'the `model.compile()` method.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f446f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "seed_num = 42\n",
    "# ---------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "\n",
    "def get_model(seed_num):\n",
    "    tf.random.set_seed(seed_num)\n",
    "\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.01, decay=0.1)\n",
    "    lstm.compile(optimizer= optimizer, loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e3c6fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49/49 [==============================] - 8s 69ms/step - loss: 1.0956e-04 - acc: 0.5977\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 3s 65ms/step - loss: 1.0880e-04 - acc: 0.6098\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 3s 65ms/step - loss: 1.0895e-04 - acc: 0.6100\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 3s 65ms/step - loss: 1.0871e-04 - acc: 0.6082\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 3s 64ms/step - loss: 1.0874e-04 - acc: 0.6085\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 3s 65ms/step - loss: 1.0867e-04 - acc: 0.6093\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 3s 64ms/step - loss: 1.0875e-04 - acc: 0.6113\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 3s 65ms/step - loss: 1.0856e-04 - acc: 0.6110\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 3s 63ms/step - loss: 1.0909e-04 - acc: 0.6095\n",
      "Epoch 10/50\n",
      " 6/49 [==>...........................] - ETA: 2s - loss: 1.0884e-04 - acc: 0.6029"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-99148fa6f6e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlstm_Predictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_Predictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-212c7fd4825c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-212c7fd4825c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_Predictors = KerasClassifier(build_fn=lambda:get_model(seed_num), epochs=50, batch_size=128)\n",
    "final_model = AdaBoostClassifier(lstm_Predictors, n_estimators=3, random_state=42, learning_rate=0.01)\n",
    "final_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a5000",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = final_model.predict(X_test) # 분류결과 return \n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be70c5",
   "metadata": {},
   "source": [
    "# Voting-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9d7693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('model1', <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4f07b8310>), ('model2', <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4f074fb80>)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics \n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "seed_num = 42\n",
    "# ---------------------------\n",
    "\n",
    "tf.random.set_seed(seed_num)\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "lstm.compile(optimizer= \"adam\", loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "\n",
    "estimator = []\n",
    "for i in range(1,3):\n",
    "    LSTM_Predictors = KerasClassifier(build_fn=lambda:lstm, epochs=10, batch_size=256)\n",
    "    LSTM_Predictors._estimator_type=\"classifier\"\n",
    "    estimator.append((f'model{i}', LSTM_Predictors))\n",
    "print(estimator) \n",
    "voting_model = VotingClassifier(estimators=estimator, voting = 'soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe0102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 7s 119ms/step - loss: 0.6792 - acc: 0.6000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.6717 - acc: 0.6106\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 0.6600 - acc: 0.6136\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.5721 - acc: 0.7048\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.4840 - acc: 0.7800\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 0.4280 - acc: 0.8120\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 0.3964 - acc: 0.8310\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.3563 - acc: 0.8598\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.3351 - acc: 0.8701\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 3s 114ms/step - loss: 0.3149 - acc: 0.8816\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 3s 93ms/step - loss: 0.3072 - acc: 0.8834\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 0.2809 - acc: 0.9031\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.2883 - acc: 0.8924\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.2516 - acc: 0.9148\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.2268 - acc: 0.9258\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.2207 - acc: 0.9264\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.2208 - acc: 0.9259\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.2021 - acc: 0.9371\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.1904 - acc: 0.9413\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 0.1778 - acc: 0.9439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4f07b8310>),\n",
       "                             ('model2',\n",
       "                              <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4f074fb80>)],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ccdb774",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7527508090614887\n"
     ]
    }
   ],
   "source": [
    "preds = voting_model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "201.563px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
