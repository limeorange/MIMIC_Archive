{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd12a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cadae5",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebece621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6182, 10, 4069), (6182,), (1545, 10, 4069), (1545,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random    \n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4069).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51f74f",
   "metadata": {},
   "source": [
    "# MAE (평균절대오차)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa0bba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "37/37 [==============================] - 13s 88ms/step - loss: 0.6801 - acc: 0.5915 - val_loss: 0.6654 - val_acc: 0.6177\n",
      "Epoch 2/500\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 0.6742 - acc: 0.6036 - val_loss: 0.6482 - val_acc: 0.6177\n",
      "Epoch 3/500\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 0.6379 - acc: 0.6298 - val_loss: 0.5525 - val_acc: 0.7354\n",
      "Epoch 4/500\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 0.5246 - acc: 0.7497 - val_loss: 0.5088 - val_acc: 0.7613\n",
      "Epoch 5/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.4379 - acc: 0.8068 - val_loss: 0.5021 - val_acc: 0.7697\n",
      "Epoch 6/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.3770 - acc: 0.8549 - val_loss: 0.5496 - val_acc: 0.7691\n",
      "Epoch 7/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.3455 - acc: 0.8682 - val_loss: 0.5499 - val_acc: 0.7652\n",
      "Epoch 8/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.3107 - acc: 0.8889 - val_loss: 0.6018 - val_acc: 0.7561\n",
      "Epoch 9/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.3035 - acc: 0.8865 - val_loss: 0.5770 - val_acc: 0.7678\n",
      "Epoch 10/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.3018 - acc: 0.8858 - val_loss: 0.6179 - val_acc: 0.7342\n",
      "Epoch 11/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2905 - acc: 0.8885 - val_loss: 0.6155 - val_acc: 0.7458\n",
      "Epoch 12/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.2647 - acc: 0.9106 - val_loss: 0.6302 - val_acc: 0.7309\n",
      "Epoch 13/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.2794 - acc: 0.8968 - val_loss: 0.6412 - val_acc: 0.7464\n",
      "Epoch 14/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2715 - acc: 0.8985 - val_loss: 0.6775 - val_acc: 0.7451\n",
      "Epoch 15/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.2569 - acc: 0.9110 - val_loss: 0.7032 - val_acc: 0.7471\n",
      "Epoch 16/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.2271 - acc: 0.9249 - val_loss: 0.7252 - val_acc: 0.7503\n",
      "Epoch 17/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.2154 - acc: 0.9350 - val_loss: 0.7507 - val_acc: 0.7510\n",
      "Epoch 18/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2109 - acc: 0.9352 - val_loss: 0.8704 - val_acc: 0.7277\n",
      "Epoch 19/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2679 - acc: 0.9029 - val_loss: 0.8798 - val_acc: 0.7212\n",
      "Epoch 20/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.3882 - acc: 0.8392 - val_loss: 0.5583 - val_acc: 0.7587\n",
      "Epoch 21/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2909 - acc: 0.8940 - val_loss: 0.5726 - val_acc: 0.7542\n",
      "Epoch 22/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.2109 - acc: 0.9313 - val_loss: 0.6388 - val_acc: 0.7555\n",
      "Epoch 23/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1921 - acc: 0.9395 - val_loss: 0.6792 - val_acc: 0.7477\n",
      "Epoch 24/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1746 - acc: 0.9478 - val_loss: 0.7240 - val_acc: 0.7445\n",
      "Epoch 25/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1567 - acc: 0.9548 - val_loss: 0.7545 - val_acc: 0.7471\n",
      "Epoch 26/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1376 - acc: 0.9654 - val_loss: 0.7859 - val_acc: 0.7477\n",
      "Epoch 27/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1219 - acc: 0.9682 - val_loss: 0.8115 - val_acc: 0.7426\n",
      "Epoch 28/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1118 - acc: 0.9707 - val_loss: 0.8344 - val_acc: 0.7426\n",
      "Epoch 29/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1065 - acc: 0.9748 - val_loss: 0.8598 - val_acc: 0.7419\n",
      "Epoch 30/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1020 - acc: 0.9757 - val_loss: 0.8826 - val_acc: 0.7432\n",
      "Epoch 31/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.0974 - acc: 0.9778 - val_loss: 0.9026 - val_acc: 0.7367\n",
      "Epoch 32/500\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 0.0931 - acc: 0.9770 - val_loss: 0.9245 - val_acc: 0.7380\n",
      "Epoch 33/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.0889 - acc: 0.9808 - val_loss: 0.9369 - val_acc: 0.7374\n",
      "Epoch 34/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.0853 - acc: 0.9803 - val_loss: 0.9541 - val_acc: 0.7374\n",
      "Epoch 35/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.0827 - acc: 0.9812 - val_loss: 0.9664 - val_acc: 0.7413\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4069/4069 [40:05<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed_num = 42\n",
    "tf.random.set_seed(seed_num)\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ep = 500\n",
    "pa = 30\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=pa, verbose=1, restore_best_weights=True)\n",
    "lstm.compile(optimizer= \"adam\", loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "lstm.fit(X_train, y_train, validation_split=0.25, batch_size=128, epochs=ep, callbacks=[early_stop], shuffle=False)\n",
    "\n",
    "# COLS\n",
    "a = pd.read_csv('total_data.csv')\n",
    "COLS = list(a['ITEMID'].sort_values().unique())\n",
    "\n",
    "results=[]\n",
    "\n",
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "with gpu_strategy.scope():\n",
    "    for k in tqdm(range(len(COLS))):\n",
    "\n",
    "        # SHUFFLE FEATURE K\n",
    "        save_col = X_test[:,:,k].copy()\n",
    "        np.random.shuffle(X_test[:,:,k])\n",
    "\n",
    "        # COMPUTE MAE WITH FEATURE K SHUFFLED\n",
    "        preds = lstm.predict(X_test, verbose=0)\n",
    "        mae = np.mean(np.abs(preds-y_test))\n",
    "\n",
    "        results.append({'feature':COLS[k],'mae':mae})\n",
    "        X_test[:,:,k] = save_col\n",
    "        \n",
    "        # DISPLAY LSTM FEATURE IMPORTANCE\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1975b139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>51006</td>\n",
       "      <td>0.471799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>51277</td>\n",
       "      <td>0.471801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>50912</td>\n",
       "      <td>0.472565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>50882</td>\n",
       "      <td>0.472682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50868</td>\n",
       "      <td>0.473135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50861</td>\n",
       "      <td>0.474062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>51221</td>\n",
       "      <td>0.474088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>51249</td>\n",
       "      <td>0.474104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>51237</td>\n",
       "      <td>0.474128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.474750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4069 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature       mae\n",
       "121    51006  0.471799\n",
       "206    51277  0.471801\n",
       "56     50912  0.472565\n",
       "34     50882  0.472682\n",
       "26     50868  0.473135\n",
       "..       ...       ...\n",
       "19     50861  0.474062\n",
       "174    51221  0.474088\n",
       "187    51249  0.474104\n",
       "182    51237  0.474128\n",
       "0          0  0.474750\n",
       "\n",
       "[4069 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ae0dd",
   "metadata": {},
   "source": [
    "# Binary Crossentropy\n",
    "- 학습 시 loss에 'binary_crossentropy'대신 tf.keras.losses.BinaryCrossentropy()\n",
    "- LSTM2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63433c0",
   "metadata": {},
   "source": [
    "## seed_num = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random    \n",
    "# ---------------------\n",
    "seed_num = 42\n",
    "# ---------------------\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4069).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ---------------------\n",
    "seed_num = 42\n",
    "# ---------------------\n",
    "tf.random.set_seed(seed_num)\n",
    "\n",
    "lstm2 = Sequential()\n",
    "lstm2.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "lstm2.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm2.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm2.add(Dropout(0.2))\n",
    "lstm2.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm2.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "lstm2.add(Dropout(0.2))\n",
    "lstm2.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ep = 500\n",
    "pa = 30\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=pa, verbose=1, restore_best_weights=True)\n",
    "lstm2.compile(optimizer= \"adam\", loss=tf.keras.losses.BinaryCrossentropy(), metrics=['acc'])\n",
    "lstm2.fit(X_train, y_train, validation_split=0.25, batch_size=128, epochs=ep, callbacks=[early_stop], shuffle=False)\n",
    "\n",
    "# COLS\n",
    "a = pd.read_csv('total_data.csv')\n",
    "COLS = list(a['ITEMID'].sort_values().unique())\n",
    "\n",
    "results = []\n",
    "preds = lstm2.predict(X_test, verbose=0)\n",
    "\n",
    "# COMPUTE BASELINE (NO SHUFFLE)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "bce = BinaryCrossentropy()\n",
    "baseline_bce = bce(y_test, preds).numpy()\n",
    "results.append({'feature':'BASELINE','baseline_bce':baseline_bce}) \n",
    "\n",
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "with gpu_strategy.scope():\n",
    "    for k in tqdm(range(len(COLS))):\n",
    "\n",
    "        # SHUFFLE FEATURE K\n",
    "        save_col = X_test[:,:,k].copy()\n",
    "        np.random.shuffle(X_test[:,:,k])\n",
    "\n",
    "        # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n",
    "        preds = lstm2.predict(X_test, verbose=0)\n",
    "        loss_bce = bce(y_test, preds).numpy()\n",
    "\n",
    "        results.append({'feature':COLS[k],'bce':loss_bce})\n",
    "        X_test[:,:,k] = save_col\n",
    "\n",
    "        # DISPLAY LSTM FEATURE IMPORTANCE\n",
    "        df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a6399",
   "metadata": {},
   "source": [
    "## seed_num = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84065b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "37/37 [==============================] - 8s 81ms/step - loss: 0.6778 - acc: 0.5840 - val_loss: 0.6668 - val_acc: 0.6138\n",
      "Epoch 2/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.6729 - acc: 0.6126 - val_loss: 0.6514 - val_acc: 0.6138\n",
      "Epoch 3/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.6251 - acc: 0.6507 - val_loss: 0.5289 - val_acc: 0.7393\n",
      "Epoch 4/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.4807 - acc: 0.7853 - val_loss: 0.5288 - val_acc: 0.7316\n",
      "Epoch 5/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.4315 - acc: 0.8126 - val_loss: 0.4821 - val_acc: 0.7762\n",
      "Epoch 6/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.3618 - acc: 0.8584 - val_loss: 0.5011 - val_acc: 0.7736\n",
      "Epoch 7/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.3250 - acc: 0.8795 - val_loss: 0.5261 - val_acc: 0.7723\n",
      "Epoch 8/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2870 - acc: 0.8971 - val_loss: 0.5674 - val_acc: 0.7620\n",
      "Epoch 9/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2548 - acc: 0.9130 - val_loss: 0.5971 - val_acc: 0.7620\n",
      "Epoch 10/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2397 - acc: 0.9209 - val_loss: 0.6172 - val_acc: 0.7516\n",
      "Epoch 11/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2398 - acc: 0.9143 - val_loss: 0.6290 - val_acc: 0.7555\n",
      "Epoch 12/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.2044 - acc: 0.9322 - val_loss: 0.6574 - val_acc: 0.7510\n",
      "Epoch 13/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.2188 - acc: 0.9259 - val_loss: 0.8719 - val_acc: 0.6798\n",
      "Epoch 14/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.3361 - acc: 0.8660 - val_loss: 0.7100 - val_acc: 0.7096\n",
      "Epoch 15/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.3132 - acc: 0.8687 - val_loss: 0.5918 - val_acc: 0.7568\n",
      "Epoch 16/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1992 - acc: 0.9371 - val_loss: 0.6716 - val_acc: 0.7555\n",
      "Epoch 17/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1681 - acc: 0.9480 - val_loss: 0.7415 - val_acc: 0.7439\n",
      "Epoch 18/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1574 - acc: 0.9523 - val_loss: 0.7801 - val_acc: 0.7439\n",
      "Epoch 19/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1529 - acc: 0.9582 - val_loss: 0.8049 - val_acc: 0.7419\n",
      "Epoch 20/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1416 - acc: 0.9605 - val_loss: 0.8186 - val_acc: 0.7387\n",
      "Epoch 21/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1336 - acc: 0.9639 - val_loss: 0.8416 - val_acc: 0.7406\n",
      "Epoch 22/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1380 - acc: 0.9632 - val_loss: 0.8231 - val_acc: 0.7413\n",
      "Epoch 23/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1529 - acc: 0.9497 - val_loss: 0.8441 - val_acc: 0.7387\n",
      "Epoch 24/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1760 - acc: 0.9395 - val_loss: 0.8049 - val_acc: 0.7393\n",
      "Epoch 25/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1496 - acc: 0.9490 - val_loss: 0.8035 - val_acc: 0.7361\n",
      "Epoch 26/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1341 - acc: 0.9567 - val_loss: 0.9530 - val_acc: 0.7012\n",
      "Epoch 27/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1689 - acc: 0.9404 - val_loss: 0.8301 - val_acc: 0.7374\n",
      "Epoch 28/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1407 - acc: 0.9535 - val_loss: 0.8470 - val_acc: 0.7393\n",
      "Epoch 29/500\n",
      "37/37 [==============================] - 2s 53ms/step - loss: 0.1128 - acc: 0.9685 - val_loss: 0.8767 - val_acc: 0.7426\n",
      "Epoch 30/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1078 - acc: 0.9681 - val_loss: 0.8971 - val_acc: 0.7354\n",
      "Epoch 31/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1129 - acc: 0.9697 - val_loss: 0.8987 - val_acc: 0.7400\n",
      "Epoch 32/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1276 - acc: 0.9616 - val_loss: 0.9783 - val_acc: 0.7322\n",
      "Epoch 33/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1630 - acc: 0.9396 - val_loss: 0.9807 - val_acc: 0.7238\n",
      "Epoch 34/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1875 - acc: 0.9271 - val_loss: 0.8503 - val_acc: 0.7406\n",
      "Epoch 35/500\n",
      "37/37 [==============================] - 2s 52ms/step - loss: 0.1652 - acc: 0.9378 - val_loss: 0.9767 - val_acc: 0.7031\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4069/4069 [44:44<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import random    \n",
    "# ---------------------\n",
    "seed_num = 44\n",
    "# ---------------------\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4069).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ---------------------\n",
    "seed_num = 44\n",
    "# ---------------------\n",
    "tf.random.set_seed(seed_num)\n",
    "\n",
    "lstm2 = Sequential()\n",
    "lstm2.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "lstm2.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm2.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm2.add(Dropout(0.2))\n",
    "lstm2.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm2.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "lstm2.add(Dropout(0.2))\n",
    "lstm2.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ep = 500\n",
    "pa = 30\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=pa, verbose=1, restore_best_weights=True)\n",
    "lstm2.compile(optimizer= \"adam\", loss=tf.keras.losses.BinaryCrossentropy(), metrics=['acc'])\n",
    "lstm2.fit(X_train, y_train, validation_split=0.25, batch_size=128, epochs=ep, callbacks=[early_stop], shuffle=False)\n",
    "\n",
    "# COLS\n",
    "a = pd.read_csv('total_data.csv')\n",
    "COLS = list(a['ITEMID'].sort_values().unique())\n",
    "\n",
    "results = []\n",
    "preds = lstm2.predict(X_test, verbose=0)\n",
    "\n",
    "# COMPUTE BASELINE (NO SHUFFLE)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "bce = BinaryCrossentropy()\n",
    "baseline_bce = bce(y_test, preds).numpy()\n",
    "results.append({'feature':'BASELINE','baseline_bce':baseline_bce}) \n",
    "\n",
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "with gpu_strategy.scope():\n",
    "    for k in tqdm(range(len(COLS))):\n",
    "\n",
    "        # SHUFFLE FEATURE K\n",
    "        save_col = X_test[:,:,k].copy()\n",
    "        np.random.shuffle(X_test[:,:,k])\n",
    "\n",
    "        # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n",
    "        preds = lstm2.predict(X_test, verbose=0)\n",
    "        loss_bce = bce(y_test, preds).numpy()\n",
    "\n",
    "        results.append({'feature':COLS[k],'bce':loss_bce})\n",
    "        X_test[:,:,k] = save_col\n",
    "\n",
    "        # DISPLAY LSTM FEATURE IMPORTANCE\n",
    "        df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76ddad5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>baseline_bce</th>\n",
       "      <th>bce</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>63323026201</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.952192</td>\n",
       "      <td>-0.009693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>51006</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.952638</td>\n",
       "      <td>-0.009247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>51277</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.956470</td>\n",
       "      <td>-0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>50882</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.957884</td>\n",
       "      <td>-0.004001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>55390000401</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.958644</td>\n",
       "      <td>-0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>10432017002</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.962698</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>517260225</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.962861</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>487980125</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.962921</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>182853489</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.963312</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BASELINE</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  baseline_bce       bce      diff\n",
       "3834  63323026201      0.961885  0.952192 -0.009693\n",
       "122         51006      0.961885  0.952638 -0.009247\n",
       "207         51277      0.961885  0.956470 -0.005415\n",
       "35          50882      0.961885  0.957884 -0.004001\n",
       "3458  55390000401      0.961885  0.958644 -0.003241\n",
       "...           ...           ...       ...       ...\n",
       "2764  10432017002      0.961885  0.962698  0.000813\n",
       "2312    517260225      0.961885  0.962861  0.000976\n",
       "2293    487980125      0.961885  0.962921  0.001036\n",
       "1831    182853489      0.961885  0.963312  0.001427\n",
       "0        BASELINE      0.961885       NaN       NaN\n",
       "\n",
       "[4070 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "df1['baseline_bce'] = float(df['baseline_bce'].dropna().unique())\n",
    "df1['diff'] = df1['bce']-df1['baseline_bce']\n",
    "df1 = df1.sort_values(by='diff')\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180.451px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
